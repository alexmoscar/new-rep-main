{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data_ford_price.xlsx') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала сформируем baseline-модель. Проведём следующую предобработку: для простоты уберём категориальные столбцы из данных и затем удалим строки с пропусками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>odometer</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>43500</td>\n",
       "      <td>36.471500</td>\n",
       "      <td>-82.483400</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>98131</td>\n",
       "      <td>40.468826</td>\n",
       "      <td>-74.281734</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>201803</td>\n",
       "      <td>42.477134</td>\n",
       "      <td>-82.949564</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>170305</td>\n",
       "      <td>40.764373</td>\n",
       "      <td>-82.349503</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>167662</td>\n",
       "      <td>45.518031</td>\n",
       "      <td>-122.578752</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  cylinders  odometer        lat        long  weather\n",
       "0  2016          6     43500  36.471500  -82.483400     59.0\n",
       "1  2009          8     98131  40.468826  -74.281734     52.0\n",
       "2  2002          8    201803  42.477134  -82.949564     45.0\n",
       "3  2000          8    170305  40.764373  -82.349503     49.0\n",
       "5  2003          8    167662  45.518031 -122.578752     50.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['price', 'year', 'cylinders', 'odometer' ,'lat', 'long', 'weather']]\n",
    "data.dropna(inplace = True)\n",
    " \n",
    "y = data['price']\n",
    "x = data.drop(columns='price')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4682.957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_predicted = model.predict(X_test)\n",
    " \n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настало время обработки выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "Первый алгоритм, который мы применим, — Isolation Forest, или iForest. Это алгоритм обнаружения аномалий на основе дерева.\n",
    "\n",
    "Данный метод стремится изолировать аномалии, которые немногочисленны и различаются по пространству признаков.\n",
    "\n",
    "Библиотека scikit-learn предоставляет реализацию Isolation Forest в классе IsolationForest.\n",
    "\n",
    "Одним из основных гиперпараметров модели является contamination («загрязнение»), который используется для оценки количества выбросов в наборе данных. Его значение находится в диапазоне от 0.0 до 0.5 и по умолчанию равно 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4306, 6) (4306,)\n",
      "MAE: 4432.161\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import IsolationForest\n",
    " \n",
    "# ищем выбросы в обучающей выборке\n",
    "iso = IsolationForest(contamination=0.1)\n",
    "y_predicted = iso.fit_predict(X_train)\n",
    " \n",
    "# выберем все строки, которые не являются выбросами\n",
    "mask = y_predicted != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    " \n",
    "print(X_train.shape, y_train.shape)\n",
    " \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "y_predicted = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "Следующий метод — Local Outlier Factor, или LOF. Это метод, который пытается использовать идею ближайших соседей для обнаружения выбросов.\n",
    "\n",
    "Каждому примеру присваивается оценка того, насколько он изолирован от его локальных соседей. Примеры, которые наиболее отдалены от соседей, скорее всего, будут являться выбросами.\n",
    "\n",
    "Библиотека scikit-learn обеспечивает реализацию этого подхода в классе LocalOutlierFactor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3964, 6) (3964,)\n",
      "MAE: 4434.481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    " \n",
    "lof = LocalOutlierFactor()\n",
    "y_predicted = lof.fit_predict(X_train)\n",
    "\n",
    "mask = y_predicted != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    " \n",
    "print(X_train.shape, y_train.shape)\n",
    " \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "y_predicted = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "Напоследок рассмотрим Minimum Covariance Determinant, или MCD.\n",
    "\n",
    "Если входные переменные имеют гауссово распределение, то для обнаружения выбросов можно использовать простые статистические методы.\n",
    "\n",
    "Например, если набор данных имеет две входные переменные и обе они являются гауссовыми, то пространство признаков образует многомерную гауссовскую зависимость, и знание этого распределения можно использовать для определения значений, далёких от распределения.\n",
    "\n",
    "Этот подход можно обобщить, определив гиперсферу (эллипсоид), которая покрывает нормальные данные, а данные, выходящие за пределы этой формы, считаются выбросами. Эффективная реализация этого метода для многомерных данных известна как детерминант минимальной ковариации (MCD).\n",
    "\n",
    "Библиотека scikit-learn предоставляет доступ к этому методу через класс EllipticEnvelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3924, 6) (3924,)\n",
      "MAE: 4444.214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    " \n",
    "ee = EllipticEnvelope(contamination=0.01)\n",
    "y_predicted = ee.fit_predict(X_train)\n",
    "\n",
    "mask = y_predicted != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    " \n",
    "print(X_train.shape, y_train.shape)\n",
    " \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "y_predicted = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что оптимальный результат достигается с помощью древовидного алгоритма Isolation Forest, тогда как пространственные методы LOF и MCD принимают за выбросы больше данных, что приводит к ухудшению качества. Тем не менее все три метода превосходят baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
