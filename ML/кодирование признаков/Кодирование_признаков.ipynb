{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "rXuqbqHi2BSO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Z6bFot2Oeg"
      },
      "source": [
        "# Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Wkm_a7aj2Sk_"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('data_ford_price.xlsx') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "z4vgpzDc2Wlh"
      },
      "outputs": [],
      "source": [
        "y = data['price']\n",
        "X = data.drop(columns='price')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1Woo8G12avl"
      },
      "source": [
        "# Предобработка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "qAeVTF4N2YLb",
        "outputId": "bf4b235c-c2c7-4615-fcba-d27f4e021ada"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'clean'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lr \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\drvla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\drvla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
            "File \u001b[1;32mc:\\Users\\drvla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "File \u001b[1;32mc:\\Users\\drvla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
            "File \u001b[1;32mc:\\Users\\drvla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\drvla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
            "File \u001b[1;32mc:\\Users\\drvla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:1998\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   1997\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1998\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2000\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2001\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2002\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2003\u001b[0m     ):\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[0;32m   2006\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m   2007\u001b[0m         ):\n",
            "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'clean'"
          ]
        }
      ],
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Чтобы этой ошибки не возникало, необходимо закодировать данные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWNgsXjv3LTK"
      },
      "source": [
        "_______________________\n",
        "Сторонний пример"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Давайте посмотрим на кодирование признака Образование способом «один-против-всех» (one vs all):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugcPTwHa3OgT",
        "outputId": "6b79c10f-fcd0-4a8a-cd5b-434a10f23cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "категории: ['BSc' 'MSc' 'PhD' 'начальное' 'нет' 'среднее']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 1, 0],\n",
              "       [0, 1, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing  import LabelBinarizer\n",
        " \n",
        "lb = LabelBinarizer()\n",
        " \n",
        "education = ['нет', 'начальное', 'среднее', 'BSc', 'MSc', 'начальное', 'PhD']\n",
        "lb.fit(education)\n",
        " \n",
        "print('категории:', lb.classes_) \n",
        "lb.transform(['нет', 'MSc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTiDn83d3S7s"
      },
      "source": [
        "___________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посмотрим на число уникальных значений номинальных признаков title_status, transmission, drive, size и cylinders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTjBKN113APL",
        "outputId": "e1344eb5-7be9-47e2-ae5d-b0a9823adb83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Число уникальных значений призкака cylinders:  6\n",
            "Число уникальных значений призкака title_status:  5\n",
            "Число уникальных значений призкака transmission:  3\n",
            "Число уникальных значений призкака drive:  3\n",
            "Число уникальных значений призкака size:  4\n"
          ]
        }
      ],
      "source": [
        "columns_to_change = ['cylinders', 'title_status', 'transmission', 'drive', 'size']\n",
        " \n",
        "for column in columns_to_change:\n",
        " print('Число уникальных значений призкака {}: '.format(column), data[column].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Итак, нам подходит однократное кодирование. Применим его к выбранным столбцам. Так как у нас нет отдельной тестовой выборки, то мы используем только один метод — fit_transform(). В качестве аргумента передаём таблицу с выбранными для преобразования признаками.\n",
        "\n",
        "С помощью метода get_feature_names_out() получим список новых названий колонок:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDYtJ8wu3cdH",
        "outputId": "60e0daa1-f4f7-449d-e584-ea5c86c85cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cylinders_3' 'cylinders_4' 'cylinders_5' 'cylinders_6' 'cylinders_8'\n",
            " 'cylinders_10' 'title_status_clean' 'title_status_lien'\n",
            " 'title_status_missing' 'title_status_rebuilt' 'title_status_salvage'\n",
            " 'transmission_automatic' 'transmission_manual' 'transmission_other'\n",
            " 'drive_4wd' 'drive_fwd' 'drive_rwd' 'drive_nan' 'size_compact'\n",
            " 'size_full-size' 'size_mid-size' 'size_sub-compact' 'size_nan']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        " \n",
        "one_hot_encoder = OneHotEncoder()\n",
        " \n",
        "# 'учим' и сразу применяем преобразование к выборке, результат переводим в массив\n",
        "data_onehot = one_hot_encoder.fit_transform(data[columns_to_change]).toarray() \n",
        "# запишем полученные названия новых колонок в отдельную переменную\n",
        "column_names = one_hot_encoder.get_feature_names_out(columns_to_change)\n",
        "print(column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Преобразуйте полученный массив закодированных данных в формат DataFrame, явно указав имена колонок.\n",
        "В качестве индекса используйте data.index, в качестве колонок — column_names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_onehot = pd.DataFrame(data_onehot, index=data.index, columns=column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Соедините новую таблицу с исходной. Для того чтобы соединить таблицы по столбцам, необходимо явно указать axis = 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_new = pd.concat([data, data_onehot], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Удалите закодированные столбцы columns_to_change из полученной таблицы. Для удаления столбцов воспользуйтесь методом drop()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_new = data_new.drop(columns=columns_to_change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7017, 30)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_new.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посмотрим, что будет, если просто убрать все строки с пропусками в столбце weather:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>year</th>\n",
              "      <th>condition</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>odometer</th>\n",
              "      <th>title_status</th>\n",
              "      <th>transmission</th>\n",
              "      <th>drive</th>\n",
              "      <th>size</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>weather</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43900</td>\n",
              "      <td>2016</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>43500</td>\n",
              "      <td>clean</td>\n",
              "      <td>automatic</td>\n",
              "      <td>4wd</td>\n",
              "      <td>full-size</td>\n",
              "      <td>36.471500</td>\n",
              "      <td>-82.483400</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15490</td>\n",
              "      <td>2009</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>98131</td>\n",
              "      <td>clean</td>\n",
              "      <td>automatic</td>\n",
              "      <td>4wd</td>\n",
              "      <td>full-size</td>\n",
              "      <td>40.468826</td>\n",
              "      <td>-74.281734</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2495</td>\n",
              "      <td>2002</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>201803</td>\n",
              "      <td>clean</td>\n",
              "      <td>automatic</td>\n",
              "      <td>4wd</td>\n",
              "      <td>full-size</td>\n",
              "      <td>42.477134</td>\n",
              "      <td>-82.949564</td>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1300</td>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>170305</td>\n",
              "      <td>rebuilt</td>\n",
              "      <td>automatic</td>\n",
              "      <td>4wd</td>\n",
              "      <td>full-size</td>\n",
              "      <td>40.764373</td>\n",
              "      <td>-82.349503</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6995</td>\n",
              "      <td>2003</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>167662</td>\n",
              "      <td>clean</td>\n",
              "      <td>automatic</td>\n",
              "      <td>4wd</td>\n",
              "      <td>full-size</td>\n",
              "      <td>45.518031</td>\n",
              "      <td>-122.578752</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7012</th>\n",
              "      <td>22500</td>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>23500</td>\n",
              "      <td>clean</td>\n",
              "      <td>automatic</td>\n",
              "      <td>rwd</td>\n",
              "      <td>full-size</td>\n",
              "      <td>32.680700</td>\n",
              "      <td>-117.169800</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7013</th>\n",
              "      <td>5975</td>\n",
              "      <td>2005</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>clean</td>\n",
              "      <td>automatic</td>\n",
              "      <td>rwd</td>\n",
              "      <td>full-size</td>\n",
              "      <td>38.213303</td>\n",
              "      <td>-85.785762</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7014</th>\n",
              "      <td>9999</td>\n",
              "      <td>2006</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>161514</td>\n",
              "      <td>clean</td>\n",
              "      <td>automatic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>full-size</td>\n",
              "      <td>37.609783</td>\n",
              "      <td>-120.995406</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7015</th>\n",
              "      <td>10900</td>\n",
              "      <td>2011</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>164000</td>\n",
              "      <td>clean</td>\n",
              "      <td>automatic</td>\n",
              "      <td>4wd</td>\n",
              "      <td>full-size</td>\n",
              "      <td>43.140600</td>\n",
              "      <td>-93.385000</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7016</th>\n",
              "      <td>18000</td>\n",
              "      <td>2010</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>104000</td>\n",
              "      <td>clean</td>\n",
              "      <td>automatic</td>\n",
              "      <td>4wd</td>\n",
              "      <td>full-size</td>\n",
              "      <td>37.987200</td>\n",
              "      <td>-84.178900</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6837 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  year  condition  cylinders  odometer title_status transmission  \\\n",
              "0     43900  2016          4          6     43500        clean    automatic   \n",
              "1     15490  2009          2          8     98131        clean    automatic   \n",
              "2      2495  2002          2          8    201803        clean    automatic   \n",
              "3      1300  2000          1          8    170305      rebuilt    automatic   \n",
              "5      6995  2003          3          8    167662        clean    automatic   \n",
              "...     ...   ...        ...        ...       ...          ...          ...   \n",
              "7012  22500  2015          3          6     23500        clean    automatic   \n",
              "7013   5975  2005          2          8         0        clean    automatic   \n",
              "7014   9999  2006          3          8    161514        clean    automatic   \n",
              "7015  10900  2011          2          8    164000        clean    automatic   \n",
              "7016  18000  2010          2          8    104000        clean    automatic   \n",
              "\n",
              "     drive       size        lat        long  weather  \n",
              "0      4wd  full-size  36.471500  -82.483400     59.0  \n",
              "1      4wd  full-size  40.468826  -74.281734     52.0  \n",
              "2      4wd  full-size  42.477134  -82.949564     45.0  \n",
              "3      4wd  full-size  40.764373  -82.349503     49.0  \n",
              "5      4wd  full-size  45.518031 -122.578752     50.0  \n",
              "...    ...        ...        ...         ...      ...  \n",
              "7012   rwd  full-size  32.680700 -117.169800     59.0  \n",
              "7013   rwd  full-size  38.213303  -85.785762     50.0  \n",
              "7014   NaN  full-size  37.609783 -120.995406     59.0  \n",
              "7015   4wd  full-size  43.140600  -93.385000     47.0  \n",
              "7016   4wd  full-size  37.987200  -84.178900     50.0  \n",
              "\n",
              "[6837 rows x 12 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[~data['weather'].isna()]\n",
        "#Символ ~ (тильда) означает, что мы выбираем все строки датасета data, где не выполняется условие data['weather'].isna(),\n",
        "# то есть где нет пропусков в столбце 'weather'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Первым делом воспользуемся методом удаления строк с пропусками. Плюс данного метода состоит в том, что модель, обученная с удалением всех пропущенных значений, является надёжной, то есть имеет сравнительно хорошее качество на тесте. Среди минусов — потеря большого количества информации, а также плохое качество работы, если процент отсутствующих значений слишком велик по сравнению с полным набором данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В качестве регрессора воспользуемся линейной моделью, а качество оценим с помощью коэффициента детерминации. Также нам потребуется разделить модель на обучающую и тестовую выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "x = data.dropna()\n",
        "y = y.iloc[x.index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Разделим выборку на тренировочную и тестовую в соотношении 80/20:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Проведём кодирование OneHot-методом категориальных переменных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучаем энкодер и сразу применяем преобразование к выборке. Результат переводим в массив:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_onehot = one_hot_encoder.fit_transform(X_train[columns_to_change]).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Затем применяем полученное преобразование к тестовой выборке. Результат переводим в массив:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_onehot = one_hot_encoder.transform(X_test[columns_to_change]).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для удобства сохраним полученные названия новых колонок в отдельную переменную:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['cylinders_3', 'cylinders_4', 'cylinders_5', 'cylinders_6',\n",
              "       'cylinders_8', 'cylinders_10', 'title_status_clean',\n",
              "       'title_status_lien', 'title_status_missing',\n",
              "       'title_status_rebuilt'], dtype=object)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns = one_hot_encoder.get_feature_names_out(columns_to_change)\n",
        "columns[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь у нас есть массив закодированных признаков и наша изначальная таблица. Чтобы соединить эти данные, переведём массив в формат DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_onehot_df = pd.DataFrame(X_train_onehot, columns=columns)\n",
        "X_test_onehot_df = pd.DataFrame(X_test_onehot, columns=columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Таблица X_train содержит рандомные индексы, так как мы разделили выборку на train и test. Если просто соединить X_train и X_train_onehot_df, то получится таблица, полная пропусков по причине несовпадения индексов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Переустановим индексацию в таблицах, применив подряд сразу два метода: reset_index() — для изменения индексов с рандомных на последовательные от 0 до n и drop(['index'], axis = 1) — для удаления образовавшегося столбца 'index'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.reset_index().drop(['index'], axis = 1)\n",
        "X_test = X_test.reset_index().drop(['index'], axis = 1)\n",
        " \n",
        "y_train = y_train.reset_index().drop(['index'], axis = 1)\n",
        "y_test = y_test.reset_index().drop(['index'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Объединяем таблицы и удаляем старые категориальные признаки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_new = pd.concat([X_train, X_train_onehot_df], axis=1)\n",
        "X_test_new = pd.concat([X_test, X_test_onehot_df], axis=1)\n",
        " \n",
        "X_train_new = X_train_new.drop(columns=columns_to_change)\n",
        "X_test_new = X_test_new.drop(columns=columns_to_change)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Настало время обучить модель. Для этого создаём объект класса LinearRegression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_model = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучаем модель по МНК:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_model.fit(X_train_new, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Делаем предсказание для тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_predict = lr_model.predict(X_train_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Делаем предсказание для тестовой выборки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train R^2: 1.000\n",
            "Test R^2: 1.000\n"
          ]
        }
      ],
      "source": [
        "y_test_predict = lr_model.predict(X_test_new)\n",
        "print(\"Train R^2: {:.3f}\".format(r2_score(y_train, y_train_predict)))\n",
        "print(\"Test R^2: {:.3f}\".format(r2_score(y_test, y_test_predict)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Заполним числовой столбец средним значением, округлив его до целого числа:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        " \n",
        "X_train['weather'] = X_train['weather'].fillna(np.round(np.mean(X_train['weather']),0))\n",
        "X_test['weather'] = X_test['weather'].fillna(np.round(np.mean(X_train['weather']),0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для простоты воспользуемся заполнением наиболее частым значением категориальных признаков. Для этого сначала определим их в наших признаках, использовав комбинацию методов value_counts() и head():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "drive\n",
              "4wd    0.736602\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train['drive'].value_counts(True).head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "size\n",
              "full-size    0.830089\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train['size'].value_counts(True).head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train['size'] = X_train['size'].fillna('full-size')\n",
        "X_train['drive'] = X_train['drive'].fillna('4wd')\n",
        " \n",
        "X_test['size'] = X_test['size'].fillna('full-size')\n",
        "X_test['drive'] = X_test['drive'].fillna('4wd')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "После обучения модели получился следующий результат:\n",
        "\n",
        "Train R^2: 0.649\n",
        "Test R^2: 0.465"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Приведённые методы обработки отсутствующих значений не учитывают корреляционную связь признака, содержащего пропуски, с остальными. Признаки, не имеющие NaN, можно использовать для прогнозирования пропущенных значений. Строится модель регрессии или классификации в зависимости от характера (категорийного или непрерывного) признака, имеющего пропущенное значение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импортируем необходимые модули\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Скопируем данные в отдельную переменную\n",
        "data = x.copy()\n",
        " \n",
        "# В качестве тестовой выборки возьмем строки с пропусками в признаке weather\n",
        "test_data = data[data['weather'].isnull()]\n",
        "# И удалим эти строчки из таблицы\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Определим целевой признак и факторы\n",
        "y_train = data['weather']\n",
        "X_train = data.drop(['size','weather','drive'], axis=1)\n",
        "X_test = test_data.drop(['size','weather','drive'], axis=1)\n",
        "\n",
        "# Создадим кодировщик\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "categorial_cols = ['cylinders', 'title_status', 'transmission']\n",
        "\n",
        "# Закодируем категориальные признаки (обучаем кодировщик только на тренировочной выборке)\n",
        "X_train_onehot = one_hot_encoder.fit_transform(X_train[categorial_cols]).toarray()\n",
        "X_test_onehot = one_hot_encoder.transform(X_test[categorial_cols]).toarray()\n",
        "\n",
        "# Результаты преобразуем обратно в DataFrame для удобства\n",
        "columns = one_hot_encoder.get_feature_names_out(categorial_cols)\n",
        "X_train_onehot_df = pd.DataFrame(X_train_onehot, columns=columns)\n",
        "X_test_onehot_df = pd.DataFrame(X_test_onehot, columns=columns)\n",
        "\n",
        "# Сбросим индексы таблиц\n",
        "X_train = X_train.reset_index().drop(['index'], axis = 1)\n",
        "X_test = X_test.reset_index().drop(['index'], axis = 1)\n",
        "y_train = y_train.reset_index().drop(['index'], axis = 1)\n",
        "\n",
        "# Добавим результаты кодирования к исходным таблицам\n",
        "X_train_new = pd.concat([X_train, X_train_onehot_df], axis=1)\n",
        "X_test_new = pd.concat([X_test, X_test_onehot_df], axis=1)\n",
        "\n",
        "# Удалим столбцы, которые уже были закодированы\n",
        "X_train_new = X_train_new.drop(columns=categorial_cols)\n",
        "X_test_new = X_test_new.drop(columns=categorial_cols)\n",
        "\n",
        "# Создадим модель линейной регрессии и обучим ее на задачу предсказания пропусков\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_new, y_train)\n",
        "\n",
        "# Сделаем предсказание целевой переменной (пропущенных значений в признаке weather) \n",
        "y_pred = model.predict(X_test_new)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Кодирование_признаков.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
