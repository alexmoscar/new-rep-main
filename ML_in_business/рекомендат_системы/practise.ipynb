{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69868, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df1 = pd.read_csv('shared_articles.csv')\n",
    "#Отфильтруйте данные так, чтобы остались только объекты с типом события CONTENT SHARED. Сколько таких объектов в получившейся таблице?\n",
    "df1 = df1[df1['eventType'] =='CONTENT SHARED']\n",
    "df1.shape[0]\n",
    "df2 = pd.read_csv('users_interactions.csv')\n",
    "#Давайте предварительно преобразуем столбцы personId, contentId в таблицах к строкам. Это преобразование пригодится нам в дальнейшем\n",
    "df2.personId = df2.personId.astype(str)\n",
    "df2.contentId = df2.contentId.astype(str)\n",
    "df2.contentId = df2.contentId.astype(str)\n",
    "#В колонке eventType описаны действия, которые могли совершать пользователи при взаимодействии со статьёй:\n",
    "#VIEW — просмотр,\n",
    "#LIKE — лайк,\n",
    "#COMMENT CREATED — комментарий,\n",
    "#FOLLOW — подписка,\n",
    "#BOOKMARK — добавление в закладки.\n",
    "#Однако у нас есть информация о различных действиях пользователя,\n",
    "# и на её основе мы должны создать некий универсальный индекс популярности. Составим его из реакций пользователей, придав им разные веса:\n",
    "event_type = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n",
    "#Создайте признак, который будет отражать числовой вес для взаимодействия со статьёй (в соответствии с приведёнными выше весами).\n",
    "# Вычислите среднее значение для полученного признака. \n",
    "df2['eventStrength'] = df2.eventType.apply(lambda x: event_type[x])\n",
    "df2['eventStrength'].mean()\n",
    "\n",
    "#оставьте только тех пользователей, которые взаимодействовали хотя бы с пятью статьями\n",
    "users_interactions_count_df = (\n",
    "    df2\n",
    "    .groupby(['personId', 'contentId'])\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .groupby('personId').size())\n",
    "\n",
    "users_with_enough_interactions_df = \\\n",
    "    users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
    "\n",
    "#print(len(users_with_enough_interactions_df))\n",
    "\n",
    "#Теперь оставим только те взаимодействия, которые касаются только отфильтрованных пользователей\n",
    "# (то есть тех, которые взаимодействовали как минимум с пятью статьями). Сколько всего таких взаимодействий?\n",
    "interactions_from_selected_users_df = df2.loc[np.in1d(df2.personId,\n",
    "            users_with_enough_interactions_df)]\n",
    "print(interactions_from_selected_users_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас каждое отдельное взаимодействие пользователя со статьёй выделено в отдельную запись, то есть пользователь мог просмотреть статью, лайкнуть и прокомментировать её, и всё это отразилось в трёх действиях. Давайте для удобства соединим все эти действия в некоторый коэффициент, который будет отражать интерес пользователя к статье. Так как каждому возможному действию мы ранее уже присвоили вес, то, по сути, нам нужно просто сложить все действия. Однако полученное число будет увеличиваться с количеством действий, и будет очень большой разброс возможных значений. В таких случаях обычно логарифмируют полученный результат с помощью следующей функции:\n",
    "\n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените упомянутое выше преобразование для логарифмирования к сумме весов для взаимодействия пользователя с каждой конкретной статьёй. Также сохраните для каждой пары «пользователь — статья» значение времени последнего взаимодействия.\n",
    "\n",
    "Найдите среднее по признаку с получившимися временными отсечками. Округлите результат до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470605340.0403006"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId']).eventStrength.sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index().set_index(['personId', 'contentId'])\n",
    ")\n",
    "interactions_full_df['last_timestamp'] = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId'])['timestamp'].max()\n",
    ")\n",
    "        \n",
    "interactions_full_df = interactions_full_df.reset_index()\n",
    "interactions_full_df['last_timestamp'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите данные на обучающую и тестовую выборки, выбрав в качестве временной отсечки значение 1475519545. Сколько объектов попало в обучающую выборку?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29325\n"
     ]
    }
   ],
   "source": [
    "split_ts = 1475519545\n",
    "interactions_train_df = interactions_full_df.loc[interactions_full_df.last_timestamp < split_ts].copy()\n",
    "interactions_test_df = interactions_full_df.loc[interactions_full_df.last_timestamp >= split_ts].copy()\n",
    "\n",
    "print(len(interactions_train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства дальнейшего измерения качества рекомендаций преобразуйте данные так, чтобы получить таблицу в формате, где строка соответствует пользователю, а столбцы будут истинными предпочтениями и рекомендациями в формате списков. На место пустых ячеек поместите пустые списки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_train</th>\n",
       "      <th>true_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1007001694607905623</th>\n",
       "      <td>[-5065077552540450930, -793729620925729327]</td>\n",
       "      <td>[-6623581327558800021, 1469580151036142903, 72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1032019229384696495</th>\n",
       "      <td>[-1006791494035379303, -1039912738963181810, -...</td>\n",
       "      <td>[-1415040208471067980, -2555801390963402198, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-108842214936804958</th>\n",
       "      <td>[-1196068832249300490, -133139342397538859, -1...</td>\n",
       "      <td>[-2780168264183400543, -3060116862184714437, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1130272294246983140</th>\n",
       "      <td>[-1150591229250318592, -1196068832249300490, -...</td>\n",
       "      <td>[-1606980109000976010, -1663441888197894674, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1160159014793528221</th>\n",
       "      <td>[-133139342397538859, -387651900461462767, 377...</td>\n",
       "      <td>[-3462051751080362224]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             true_train  \\\n",
       "personId                                                                  \n",
       "-1007001694607905623        [-5065077552540450930, -793729620925729327]   \n",
       "-1032019229384696495  [-1006791494035379303, -1039912738963181810, -...   \n",
       "-108842214936804958   [-1196068832249300490, -133139342397538859, -1...   \n",
       "-1130272294246983140  [-1150591229250318592, -1196068832249300490, -...   \n",
       "-1160159014793528221  [-133139342397538859, -387651900461462767, 377...   \n",
       "\n",
       "                                                              true_test  \n",
       "personId                                                                 \n",
       "-1007001694607905623  [-6623581327558800021, 1469580151036142903, 72...  \n",
       "-1032019229384696495  [-1415040208471067980, -2555801390963402198, -...  \n",
       "-108842214936804958   [-2780168264183400543, -3060116862184714437, -...  \n",
       "-1130272294246983140  [-1606980109000976010, -1663441888197894674, -...  \n",
       "-1160159014793528221                             [-3462051751080362224]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = (\n",
    "    interactions_train_df.reset_index()\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    "    .reset_index()\n",
    "    .rename(columns={'contentId': 'true_train'})\n",
    "    .set_index('personId')\n",
    ")\n",
    "\n",
    "final_df['true_test'] = (\n",
    "    interactions_test_df.reset_index()\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    ")\n",
    "\n",
    "final_df['true_test'] = [ [] if x is np.NaN else x for x in final_df['true_test'] ]\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте популярность каждой статьи как сумму всех логарифмических «оценок» взаимодействий с ней (используя только обучающую выборку). Выберите ID самой популярной статьи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-6783772548752091658'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular = (\n",
    "    interactions_train_df\n",
    "    .groupby('contentId')\n",
    "    .eventStrength.sum().reset_index()\n",
    "    .sort_values('eventStrength', ascending=False)\n",
    "    .contentId.values\n",
    ")\n",
    "popular[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо сформировать рекомендации для каждого пользователя. Будем рекомендовать десять самых популярных статей. Также необходимо помнить, что следует предлагать пользователю только то, что он ещё не читал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте систему рекомендаций. Оцените качество с помощью precision@10 для каждого пользователя (доля угаданных рекомендаций). После этого усредните результат по всем пользователям.\n",
    "\n",
    "Для вычисления precision@10 воспользуйтесь следующей функцией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006454207722621089"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 10\n",
    " \n",
    "final_df['popular'] = (\n",
    "    final_df.true_train\n",
    "    .apply(\n",
    "        lambda x:\n",
    "        popular[~np.in1d(popular, x)][:top_k]\n",
    "    )\n",
    ")\n",
    "def calc_precision(column):\n",
    "    return (\n",
    "        final_df\n",
    "        .apply(\n",
    "            lambda row:\n",
    "            len(set(row['true_test']).intersection(\n",
    "                set(row[column]))) /\n",
    "            min(len(row['true_test']) + 0.001, 10.0),\n",
    "            axis=1)).mean()\n",
    "calc_precision('popular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Стоит отметить, что качество РС оценивается не так, как в задачах классификации: показателей выше 0.5 добиться практически невозможно, и даже результат 0.1–0.2 — индикатор высокого качества."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
